{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b483263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (2.19.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from datasets) (3.4.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.21.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets) (3.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.1.2)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.4.1)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.29.4)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.8/site-packages (from jupyter) (5.5.1)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.3.0)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.30.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (59.4.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.8.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.5.4)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (26.0.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (7.1.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (21.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.8.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (5.1.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.9)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->jupyter) (2.0.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (4.2.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (0.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.18.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (21.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (3.6.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (21.1.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->ipykernel->jupyter) (3.0.6)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install --upgrade jupyter ipywidgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f37f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch, transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "import pandas as pd, numpy as np\n",
    "from torch import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a7458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May  3 13:04:03 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    On  | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   22C    P8               8W / 300W |      4MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d1072f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#global params for training\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", padding = True, return_tensors = \"pt\",is_split_into_words=True)\n",
    "batch_size = 64\n",
    "epoch = 100\n",
    "max_tokenizer_len = 512\n",
    "\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a20f1081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/datasets/load.py:1486: FutureWarning: The repository for knowledgator/events_classification_biotech contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/knowledgator/events_classification_biotech\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd, numpy as np\n",
    "    \n",
    "dataset = load_dataset('knowledgator/events_classification_biotech') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19dd7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content', 'target organization', 'all_labels', 'all_labels_concat', 'label 1', 'label 2', 'label 3', 'label 4', 'label 5'],\n",
       "        num_rows: 2759\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'content', 'target organization', 'all_labels', 'all_labels_concat', 'label 1', 'label 2', 'label 3', 'label 4', 'label 5'],\n",
       "        num_rows: 381\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3e0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_temp = pd.DataFrame(dataset['train'])\n",
    "test_df_temp = pd.DataFrame(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d063d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['content' , 'all_labels']\n",
    "train_df = train_df_temp[cols].copy()\n",
    "test_df = test_df_temp[cols].copy()\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "716ae185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hiring', 'foundation', 'clinical trial sponsorship', 'alliance & partnership', 'article publication', 'patent publication', 'department establishment', 'subsidiary establishment', 'closing', 'new initiatives or programs', 'other', 'product launching & presentation', 'company description', 'executive statement', 'new initiatives & programs', 'funding round', 'partnerships & alliances', 'm&a', 'expanding geography', 'expanding industry', 'event organization', 'executive appointment', 'investment in public company', 'participation in an event', 'regulatory approval', 'product updates', 'support & philanthropy', 'service & product providing', 'ipo exit']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_values_count = train_df['all_labels']\n",
    "#print(distinct_values_count)\n",
    "all_vals = (list(distinct_values_count))\n",
    "concatenated_list = [item for sublist in all_vals for item in sublist]\n",
    "#print(concatenated_list)\n",
    "list_labels = list(set(sorted(concatenated_list)))\n",
    "print(list_labels)\n",
    "list_labels.index('other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3ec872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'foundation',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'investment in public company',\n",
       " 'company description',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'support & philanthropy',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'investment in public company',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'm&a',\n",
       " 'new initiatives or programs',\n",
       " 'expanding industry',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'investment in public company',\n",
       " 'other',\n",
       " 'other',\n",
       " 'm&a',\n",
       " 'partnerships & alliances',\n",
       " 'product launching & presentation',\n",
       " 'expanding geography',\n",
       " 'm&a',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'other',\n",
       " 'other',\n",
       " 'm&a',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'm&a',\n",
       " 'executive statement',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'new initiatives & programs',\n",
       " 'executive statement',\n",
       " 'other',\n",
       " 'm&a',\n",
       " 'executive statement',\n",
       " 'other',\n",
       " 'other',\n",
       " 'investment in public company',\n",
       " 'expanding geography',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'executive statement',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'executive statement',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'hiring',\n",
       " 'other',\n",
       " 'other',\n",
       " 'executive statement',\n",
       " 'executive appointment',\n",
       " 'expanding geography',\n",
       " 'alliance & partnership',\n",
       " 'service & product providing',\n",
       " 'executive statement',\n",
       " 'm&a',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'article publication',\n",
       " 'expanding geography',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'product updates',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'expanding geography',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'product launching & presentation',\n",
       " 'company description',\n",
       " 'company description',\n",
       " 'participation in an event',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'regulatory approval',\n",
       " 'expanding geography',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'article publication',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'product updates',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'm&a',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'product launching & presentation',\n",
       " 'alliance & partnership',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'regulatory approval',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'regulatory approval',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'article publication',\n",
       " 'company description',\n",
       " 'ipo exit',\n",
       " 'm&a',\n",
       " 'product launching & presentation',\n",
       " 'article publication',\n",
       " 'm&a',\n",
       " 'department establishment',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'investment in public company',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'service & product providing',\n",
       " 'product updates',\n",
       " 'regulatory approval',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'product updates',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'funding round',\n",
       " 'alliance & partnership',\n",
       " 'new initiatives or programs',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'hiring',\n",
       " 'alliance & partnership',\n",
       " 'service & product providing',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'expanding geography',\n",
       " 'article publication',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'expanding geography',\n",
       " 'investment in public company',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'clinical trial sponsorship',\n",
       " 'executive statement',\n",
       " 'executive appointment',\n",
       " 'company description',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'new initiatives or programs',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'funding round',\n",
       " 'new initiatives or programs',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'hiring',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'company description',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'article publication',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'expanding geography',\n",
       " 'executive statement',\n",
       " 'expanding geography',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'company description',\n",
       " 'product launching & presentation',\n",
       " 'participation in an event',\n",
       " 'executive statement',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'hiring',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'executive appointment',\n",
       " 'company description',\n",
       " 'funding round',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'm&a',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'new initiatives or programs',\n",
       " 'new initiatives & programs',\n",
       " 'alliance & partnership',\n",
       " 'support & philanthropy',\n",
       " 'participation in an event',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'executive appointment',\n",
       " 'company description',\n",
       " 'company description',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'article publication',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'article publication',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'new initiatives & programs',\n",
       " 'alliance & partnership',\n",
       " 'service & product providing',\n",
       " 'investment in public company',\n",
       " 'company description',\n",
       " 'hiring',\n",
       " 'alliance & partnership',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'company description',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'regulatory approval',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'product launching & presentation',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'm&a',\n",
       " 'product updates',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'new initiatives or programs',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'service & product providing',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'funding round',\n",
       " 'regulatory approval',\n",
       " 'new initiatives or programs',\n",
       " 'product updates',\n",
       " 'patent publication',\n",
       " 'regulatory approval',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'investment in public company',\n",
       " 'company description',\n",
       " 'service & product providing',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'hiring',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'article publication',\n",
       " 'executive appointment',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'article publication',\n",
       " 'alliance & partnership',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'clinical trial sponsorship',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'investment in public company',\n",
       " 'expanding geography',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'service & product providing',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'service & product providing',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'new initiatives or programs',\n",
       " 'executive statement',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'm&a',\n",
       " 'alliance & partnership',\n",
       " 'new initiatives or programs',\n",
       " 'article publication',\n",
       " 'alliance & partnership',\n",
       " 'm&a',\n",
       " 'expanding geography',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'expanding industry',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'article publication',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'article publication',\n",
       " 'alliance & partnership',\n",
       " 'event organization',\n",
       " 'company description',\n",
       " 'new initiatives & programs',\n",
       " 'executive statement',\n",
       " 'new initiatives or programs',\n",
       " 'executive statement',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'expanding geography',\n",
       " 'ipo exit',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'hiring',\n",
       " 'm&a',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'executive appointment',\n",
       " 'expanding geography',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'expanding geography',\n",
       " 'executive statement',\n",
       " 'event organization',\n",
       " 'company description',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'article publication',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'article publication',\n",
       " 'new initiatives or programs',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'company description',\n",
       " 'investment in public company',\n",
       " 'expanding geography',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'product launching & presentation',\n",
       " 'new initiatives or programs',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'service & product providing',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'product launching & presentation',\n",
       " 'alliance & partnership',\n",
       " 'executive appointment',\n",
       " 'product launching & presentation',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'funding round',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'product launching & presentation',\n",
       " 'company description',\n",
       " 'funding round',\n",
       " 'investment in public company',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'expanding geography',\n",
       " 'funding round',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'expanding industry',\n",
       " 'new initiatives or programs',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'new initiatives or programs',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'investment in public company',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'm&a',\n",
       " 'expanding geography',\n",
       " 'executive statement',\n",
       " 'service & product providing',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'new initiatives & programs',\n",
       " 'company description',\n",
       " 'company description',\n",
       " 'expanding geography',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'service & product providing',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'm&a',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'new initiatives or programs',\n",
       " 'alliance & partnership',\n",
       " 'company description',\n",
       " 'product launching & presentation',\n",
       " 'investment in public company',\n",
       " 'company description',\n",
       " 'funding round',\n",
       " 'new initiatives or programs',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'participation in an event',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'executive appointment',\n",
       " 'product launching & presentation',\n",
       " 'participation in an event',\n",
       " 'expanding geography',\n",
       " 'new initiatives or programs',\n",
       " 'executive statement',\n",
       " 'executive appointment',\n",
       " 'executive statement',\n",
       " 'm&a',\n",
       " 'ipo exit',\n",
       " 'new initiatives or programs',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'expanding geography',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'new initiatives or programs',\n",
       " 'expanding industry',\n",
       " 'expanding geography',\n",
       " 'closing',\n",
       " 'executive statement',\n",
       " 'product launching & presentation',\n",
       " 'service & product providing',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'new initiatives & programs',\n",
       " 'event organization',\n",
       " 'new initiatives & programs',\n",
       " 'new initiatives or programs',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'hiring',\n",
       " 'hiring',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'new initiatives or programs',\n",
       " 'product launching & presentation',\n",
       " 'alliance & partnership',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'm&a',\n",
       " 'company description',\n",
       " 'funding round',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'funding round',\n",
       " 'alliance & partnership',\n",
       " 'expanding geography',\n",
       " 'executive statement',\n",
       " 'funding round',\n",
       " 'new initiatives or programs',\n",
       " 'executive statement',\n",
       " 'm&a',\n",
       " 'participation in an event',\n",
       " 'executive statement',\n",
       " 'event organization',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'support & philanthropy',\n",
       " 'executive statement',\n",
       " 'investment in public company',\n",
       " 'company description',\n",
       " 'product launching & presentation',\n",
       " 'new initiatives or programs',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'company description',\n",
       " 'executive statement',\n",
       " 'alliance & partnership',\n",
       " 'service & product providing',\n",
       " 'new initiatives or programs',\n",
       " 'executive statement',\n",
       " 'm&a',\n",
       " 'executive statement',\n",
       " 'executive statement',\n",
       " 'company description',\n",
       " 'alliance & partnership',\n",
       " 'regulatory approval',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ee04222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(all_labels):\n",
    "    #print(all_labels)\n",
    "    lab_list = [list_labels.index(item) for item in all_labels]\n",
    "    return lab_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d53c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['labels'] = train_df['all_labels'].apply(create_label)\n",
    "\n",
    "test_df['labels'] = test_df['all_labels'].apply(create_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d4b6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['content', 'all_labels', 'labels'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6654a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['labels','content']\n",
    "na_rows = train_df[cols].isna().any(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6c880f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_train = train_df[~na_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03170904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>all_labels</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drive Your Plow Over the Bones of The Dead\\nby...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the recently tabled National Budget, Denel ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shares\\nTake a break its good for you (Picture...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESO is currently hiring for two positions:\\nP...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charter Buyer Club\\nWhat is the Charter Buyer ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>0\\nA regional daily wants to bring an internat...</td>\n",
       "      <td>[support &amp; philanthropy, company description]</td>\n",
       "      <td>[26, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>Share on whatsapp\\nR1 RCM Inc. (NASDAQ:RCM)\\nw...</td>\n",
       "      <td>[investment in public company, company descrip...</td>\n",
       "      <td>[22, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>Verboso Launches Full-Stack Online Speech Ther...</td>\n",
       "      <td>[product launching &amp; presentation]</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>Barnet, Enfield and Haringey Mental Health Tru...</td>\n",
       "      <td>[executive statement]</td>\n",
       "      <td>[13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>Genprex, Inc.\\n(Genprex or the Company) (NASDA...</td>\n",
       "      <td>[company description]</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2758 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  \\\n",
       "0     Drive Your Plow Over the Bones of The Dead\\nby...   \n",
       "1     In the recently tabled National Budget, Denel ...   \n",
       "2     Shares\\nTake a break its good for you (Picture...   \n",
       "3     RESO is currently hiring for two positions:\\nP...   \n",
       "4     Charter Buyer Club\\nWhat is the Charter Buyer ...   \n",
       "...                                                 ...   \n",
       "2754  0\\nA regional daily wants to bring an internat...   \n",
       "2755  Share on whatsapp\\nR1 RCM Inc. (NASDAQ:RCM)\\nw...   \n",
       "2756  Verboso Launches Full-Stack Online Speech Ther...   \n",
       "2757  Barnet, Enfield and Haringey Mental Health Tru...   \n",
       "2758  Genprex, Inc.\\n(Genprex or the Company) (NASDA...   \n",
       "\n",
       "                                             all_labels    labels  \n",
       "0                                               [other]      [10]  \n",
       "1                                               [other]      [10]  \n",
       "2                                               [other]      [10]  \n",
       "3                                               [other]      [10]  \n",
       "4                                               [other]      [10]  \n",
       "...                                                 ...       ...  \n",
       "2754      [support & philanthropy, company description]  [26, 12]  \n",
       "2755  [investment in public company, company descrip...  [22, 12]  \n",
       "2756                 [product launching & presentation]      [11]  \n",
       "2757                              [executive statement]      [13]  \n",
       "2758                              [company description]      [12]  \n",
       "\n",
       "[2758 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df275cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rows_test = test_df[cols].isna().any(axis=1)\n",
    "cleaned_df_test = test_df[~na_rows_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c58e6",
   "metadata": {},
   "source": [
    "# Train Test split\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5080fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# Randomly shuffle the DataFrame\n",
    "df_shuffled = cleaned_df_train.sample(frac=1, random_state=seed)\n",
    "train_ratio = 0.8\n",
    "# Calculate the number of samples for training\n",
    "train_size = int(train_ratio * len(df_shuffled))\n",
    "\n",
    "# Split the shuffled DataFrame into training and testing sets\n",
    "df_train = df_shuffled[:train_size]\n",
    "df_val = df_shuffled[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c563ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a76a03e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 17781, 3225, 1130, 17030, 5430, 2825, 1605, 14866, 17087, 2553, 1111, 4108, 2328, 17564, 1348, 3225, 4326, 1203, 2470, 1116, 108, 122, 23089, 1419, 11458, 22233, 26616, 15468, 1106, 11125, 23089, 2616, 118, 6303, 1428, 1626, 117, 17881, 1477, 1367, 131, 3862, 27269, 197, 5313, 131, 17781, 3225, 2796, 20537, 117, 4565, 117, 7414, 12150, 10069, 23676, 13821, 9919, 18589, 2064, 2591, 4880, 24846, 2069, 4880, 24846, 117, 151, 119, 150, 119, 117, 13650, 119, 1626, 117, 17881, 1477, 113, 144, 2162, 2346, 27211, 26546, 18019, 25190, 16941, 114, 118, 118, 17781, 3225, 117, 1203, 2470, 1116, 108, 122, 2825, 1605, 14866, 1881, 117, 3055, 1850, 170, 2998, 1106, 1203, 2470, 1116, 3289, 2332, 22233, 24990, 1105, 1203, 2470, 1352, 7844, 1106, 5622, 15468, 1121, 22233, 24990, 1111, 23089, 5811, 1112, 170, 18560, 2332, 1555, 119, 1109, 4909, 1110, 170, 2593, 1106, 170, 2793, 1644, 1115, 5802, 1155, 2616, 118, 6303, 1105, 1251, 1149, 118, 1104, 118, 4480, 4692, 1111, 18560, 2332, 1826, 1105, 23897, 119, 1212, 1356, 122, 117, 17881, 1477, 117, 3279, 2617, 1955, 1559, 1245, 3903, 1106, 1294, 4910, 1105, 18560, 2332, 1826, 1167, 19017, 1111, 1203, 4112, 1116, 119, 1109, 5626, 3631, 1103, 5754, 1104, 18560, 2332, 1826, 1106, 2267, 1317, 3252, 6665, 1259, 1848, 1105, 1126, 23694, 1616, 1826, 1111, 1103, 3252, 117, 5871, 15197, 12633, 117, 13347, 1105, 9117, 1104, 4910, 6946, 1279, 117, 9556, 6704, 11759, 1105, 14780, 10122, 11759, 117, 1259, 1107, 27420, 117, 1260, 2430, 8745, 11531, 117, 5198, 3252, 117, 1105, 7597, 2704, 2734, 117, 12885, 1149, 27420, 7606, 117, 1149, 27420, 1105, 1155, 23897, 117, 1259, 4097, 118, 1271, 22759, 5557, 1165, 13179, 1116, 1132, 22254, 117, 113, 7569, 1896, 114, 119, 7199, 117, 2657, 23089, 1110, 170, 188, 19756, 21017, 11486, 4092, 15683, 1111, 170, 2783, 1104, 18560, 2332, 11759, 1259, 2112, 118, 23057, 6600, 8936, 117, 11769, 2660, 2386, 1329, 8936, 117, 5199, 1126, 4474, 19767, 117, 1105, 22195, 1116, 3653, 1223, 1103, 9086, 1105, 11845, 3291, 8223, 11192, 1988, 2193, 11696, 2173, 16992, 5766, 117, 1288, 1203, 4112, 1116, 1104, 1103, 1703, 7029, 117, 1288, 3875, 2825, 1605, 14866, 4659, 4035, 10747, 8870, 1971, 7044, 1111, 2657, 23089, 3252, 1223, 18560, 2332, 4267, 8517, 22583, 1116, 119, 17781, 3225, 13812, 1116, 1115, 1103, 1911, 1104, 2332, 22233, 24990, 6573, 1111, 2657, 23089, 1336, 3166, 2281, 1120, 1148, 18407, 117, 1103, 1565, 118, 3674, 2998, 2231, 119, 1438, 117, 1112, 17781, 3225, 1209, 6265, 2071, 117, 1122, 1110, 2140, 170, 12478, 117, 9483, 9162, 1165, 1737, 1107, 1609, 1104, 1168, 1203, 2470, 1644, 119, 1203, 2470, 1640, 5315, 3239, 9806, 22233, 24990, 1106, 2653, 1111, 2657, 23089, 117, 1105, 1203, 2470, 1640, 20554, 2657, 23089, 1103, 1269, 1112, 7228, 24259, 23897, 119, 1109, 1864, 1115, 2332, 22233, 24990, 1431, 5709, 1209, 4163, 1183, 1111, 2657, 23089, 1110, 1136, 8953, 1120, 1142, 1553, 119, 1135, 1110, 1103, 1397, 11730, 2585, 117, 1105, 1122, 1110, 170, 1353, 2585, 117, 1136, 170, 4994, 13660, 119, 1130, 14847, 1733, 1971, 2653, 1111, 2657, 23089, 1223, 1203, 2470, 1116, 8736, 3291, 8223, 5026, 1891, 2173, 117, 1134, 3643, 4475, 3239, 1106, 1329, 1105, 1129, 1231, 4060, 19364, 5591, 1111, 2657, 23089, 1165, 8012, 9483, 1105, 3238, 1920, 119, 2825, 1605, 14866, 5811, 1110, 1145, 170, 9221, 2913, 1555, 1107, 1168, 2182, 119, 1130, 1803, 117, 22233, 24990, 1971, 2653, 1111, 2657, 23089, 1194, 2332, 5257, 2714, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tokenizer:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", padding = True, return_tensors = \"pt\" , truncate = True, max_length  = 512)\n",
    "\n",
    "tokens = tokenizer(df_train['content'][100])\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c096120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d62fad98",
   "metadata": {},
   "source": [
    "### Data loaders and Dataset for batched training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a74e09b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, df,len_labels):\n",
    "        self.df = df\n",
    "        self.len = len_labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx]['content']\n",
    "        x = tokenizer.encode_plus(text,max_length= max_tokenizer_len, padding=\"max_length\",truncation=True, return_tensors=\"pt\" )\n",
    "        label_vec = np.zeros(self.len)       \n",
    "        label = torch.tensor(self.df.iloc[idx]['labels'])\n",
    "        label_vec[label] = 1\n",
    "        #take the id of the row and return tokeinzed tensors\n",
    "        #print(x.shape)\n",
    "        x_dict = {}\n",
    "        x_dict['id'] = x['input_ids']\n",
    "        x_dict['token_type'] = x['token_type_ids']\n",
    "        x_dict['attention_mask'] = x['attention_mask']\n",
    "        \n",
    "        \n",
    "        return x_dict, torch.tensor(label_vec)\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return the length of the dataframe\n",
    "        return len(self.df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16340367",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset(df_train,len(list_labels))\n",
    "val_dataset = dataset(df_val,len(list_labels))\n",
    "test_dataset = dataset(test_df,len(list_labels))\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size = batch_size, shuffle = True , num_workers = 0, pin_memory = True)\n",
    "val_loader = DataLoader(val_dataset,batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test_dataset,batch_size = batch_size, shuffle = False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e800d26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eab6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b983bac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#enc = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "# ids = torch.tensor(tokens['input_ids'])\n",
    "# t_type = torch.unsqueeze(torch.tensor(tokens['token_type_ids']), dim = 0)\n",
    "# att_m = torch.unsqueeze(torch.tensor(tokens['attention_mask']), dim = 0)\n",
    "# enc(ids, t_type,att_m, return_dict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5561e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64de74f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bfc7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clf_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(clf_model, self).__init__()\n",
    "        self.backbone = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        #self.norm_layer = torch.nn.LayerNorm()\n",
    "        self.linear_layer = torch.nn.Linear(768,len(list_labels))\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    " \n",
    "                  \n",
    "    def forward(self,ids ,token_type,att_mask):\n",
    "        #print(f\"shape of ids->{ids.shape}\")\n",
    "           #ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False     \n",
    "        _,x = self.backbone(ids , token_type_ids =token_type ,attention_mask= att_mask, return_dict=False)\n",
    "        \n",
    "        #print(f\"shape after backbone ->{x.shape}\")\n",
    "        #print(f\"x after backbone ->{x}\")\n",
    "                     \n",
    "        x = self.linear_layer(x)\n",
    "        #print(f\"shape after linear_layer->{x.shape}\")\n",
    "        #print(f\"x after linear ->{x}\")\n",
    "        layer_norm = torch.nn.LayerNorm(x.shape[1], device = 'cuda:0')\n",
    "        x = layer_norm(x)\n",
    "        #print(f\"shape x after layer norm ->{x.shape}\")\n",
    "        #print(f\"x after layer normm ->{x}\")\n",
    "        \n",
    "        logits = self.sigmoid(x)\n",
    "        del x\n",
    "        \n",
    "        #print(f\"shape of logits->{logits.shape}\")\n",
    "        #print(f\"logits = {logits}\")\n",
    "        return logits\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44127d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens \n",
    "# x_temp = torch.tensor(tokens['input_ids'][:512]).unsqueeze(dim = 0)\n",
    "# print(x_temp.shape)\n",
    "# x_att = torch.tensor(tokens['attention_mask'][:512]).unsqueeze(dim = 0)\n",
    "# x_tok_type = torch.tensor(tokens['token_type_ids'][:512]).unsqueeze(dim = 0)\n",
    "\n",
    "# x_temp_gpu = x_temp.to(device)\n",
    "# x_att_gpu = x_att.to(device)\n",
    "# x_tok_type_gpu = x_tok_type.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# m_gpu  = transformers.BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "# m_gpu.to(device)\n",
    "# m_cpu = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fae968fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# o_gpu = m_gpu(x_temp_gpu,x_att_gpu,x_tok_type_gpu)\n",
    "# o_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d93af61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_clf = clf_model()\n",
    "# m_clf.to(device)\n",
    "# t = m_clf(x_temp_gpu,x_tok_type_gpu,x_att_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "220614ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter = iter(train_loader)\n",
    "# for batch in train_loader:\n",
    "#     x_dict, y = batch\n",
    "#     ids = torch.squeeze(torch.tensor(x_dict['id']).clone().detach(),dim = 1)\n",
    "#     print(f\"shape of ids->{ids.shape}\")\n",
    "#     token_type = torch.squeeze(torch.tensor(x_dict['token_type']).clone().detach(), dim = 1)\n",
    "#     print(f\"shape of token_type->{token_type.shape}\")\n",
    "#     att_mask = torch.squeeze(torch.tensor(x_dict['attention_mask']).clone().detach(), dim = 1)\n",
    "#     print(f\"shape of att_mask->{att_mask.shape}\")\n",
    "#     logits = model(ids ,token_type,att_mask)\n",
    "#     print(logits)    \n",
    "#     print(y.shape)\n",
    "#     #input_id = batch['input_ids']\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4881b7e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_iter = iter(train_loader)\n",
    "# for batch in train_loader:\n",
    "#     x_dict, y = batch\n",
    "#     model.to(device)\n",
    "#     #print(next(model_gpu.parameters()).device)\n",
    "#     ids = torch.squeeze(torch.tensor(x_dict['id']).clone().detach(),dim = 1)\n",
    "#     print(f\"shape of ids->{ids.shape}\")\n",
    "#     token_type = torch.squeeze(torch.tensor(x_dict['token_type']).clone().detach(), dim = 1)\n",
    "#     print(f\"shape of token_type->{token_type.shape}\")\n",
    "#     att_mask = torch.squeeze(torch.tensor(x_dict['attention_mask']).clone().detach(), dim = 1)\n",
    "#     print(f\"shape of att_mask->{att_mask.shape}\")\n",
    "#     ids_gpu = ids.to(device)\n",
    "#     print(f\"ids = {ids_gpu}\")\n",
    "#             #ids.to(device)\n",
    "#     print(ids_gpu.device)\n",
    "#     token_type_gpu = token_type.to(device)\n",
    "#     print(token_type_gpu.device)\n",
    "#     att_mask_gpu = att_mask.to(device)\n",
    "#     print(att_mask_gpu.device)\n",
    "#     #label_vec.to(device)\n",
    "#     logits = model(ids_gpu ,token_type_gpu,att_mask_gpu)\n",
    "#     print(logits)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0863254",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a72f4cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a11d5145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader,optimizer, num_epoch = 100, model = clf_model()):\n",
    "    model.train()\n",
    "    for i in range (num_epoch):\n",
    "        loss_list = []\n",
    "        for ind,(x_dict, label_vec) in enumerate(train_loader):\n",
    "            model.to(device)\n",
    "            #print(next(model_gpu.parameters()).device)\n",
    "            \n",
    "            id_list = x_dict['id']\n",
    "            id_tensor = torch.squeeze(torch.tensor(id_list),dim = 1)\n",
    "            #print(f\"shape of ids->{id_tensor.shape}\")\n",
    "            \n",
    "            tok_type_list = x_dict['token_type']\n",
    "            tok_type_tensor = torch.squeeze(torch.tensor(tok_type_list),dim = 1)\n",
    "            \n",
    "            #token_type = torch.squeeze(torch.tensor(,dtype=torch.long).clone().detach(), dim = 1)\n",
    "            #print(f\"shape of token_type->{tok_type_tensor.shape}\")\n",
    "        \n",
    "            att_list = x_dict['attention_mask']\n",
    "            att_mask_tensor = torch.squeeze(torch.tensor(att_list),dim = 1)\n",
    "            #att_mask = torch.squeeze(torch.tensor(,dtype=torch.long).clone().detach(), dim = 1)\n",
    "            #print(f\"shape of att_mask->{att_mask_tensor.shape}\")\n",
    "                        \n",
    "            ids_gpu = id_tensor.to(device)\n",
    "            #print(f\"ids = {ids_gpu}\")\n",
    "            #ids.to(device)\n",
    "            #print(ids_gpu.device)\n",
    "            \n",
    "            token_type_gpu = tok_type_tensor.to(device)\n",
    "            #print(token_type_gpu.device)\n",
    "            \n",
    "            att_mask_gpu = att_mask_tensor.to(device)\n",
    "            #print(att_mask_gpu.device)\n",
    "            \n",
    "            \n",
    "            \n",
    "            labal_vec_gpu = label_vec.float().to(device)\n",
    "            #print(f\" labal_vec_gpu = {labal_vec_gpu}\")\n",
    "            \n",
    "            logits = model(ids_gpu ,token_type_gpu,att_mask_gpu)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss = nn.BCELoss()\n",
    "            output = loss(logits, labal_vec_gpu)\n",
    "            \n",
    "            #loss = torch.nn.BCEWithLogitsLoss(logits, labal_vec_gpu)\n",
    "            output.backward()\n",
    "            optimizer.step\n",
    "            loss_list.append(output.item())\n",
    "            #print(f\"batch_ind{ind} and its loss is {loss.item()}\")\n",
    "            \n",
    "        \n",
    "        print(f\" epoch= {num_epoch} and mean train loss is {torch.mean(torch.tensor(loss_list))}\")\n",
    "    \n",
    "    return model\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42ea9b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_605/591830481.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  id_tensor = torch.squeeze(torch.tensor(id_list),dim = 1)\n",
      "/tmp/ipykernel_605/591830481.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tok_type_tensor = torch.squeeze(torch.tensor(tok_type_list),dim = 1)\n",
      "/tmp/ipykernel_605/591830481.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  att_mask_tensor = torch.squeeze(torch.tensor(att_list),dim = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch= 100 and mean train loss is 0.8235846161842346\n",
      " epoch= 100 and mean train loss is 0.8234076499938965\n",
      " epoch= 100 and mean train loss is 0.8234884738922119\n",
      " epoch= 100 and mean train loss is 0.8231267333030701\n",
      " epoch= 100 and mean train loss is 0.8236042857170105\n",
      " epoch= 100 and mean train loss is 0.8236517906188965\n",
      " epoch= 100 and mean train loss is 0.8237167000770569\n",
      " epoch= 100 and mean train loss is 0.8237625956535339\n",
      " epoch= 100 and mean train loss is 0.8233580589294434\n",
      " epoch= 100 and mean train loss is 0.8233585357666016\n"
     ]
    }
   ],
   "source": [
    "model = clf_model()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-3)\n",
    "tr_model = train_model(train_loader, optimizer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfe6bf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95373c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = tensor([[ 1.5612,  1.4753],\n",
      "        [-1.3181, -2.5301],\n",
      "        [-1.2903,  0.9343]], requires_grad=True)\n",
      "target = tensor([[0.4247, 0.8626],\n",
      "        [0.3439, 0.4488],\n",
      "        [0.3545, 0.6084]])\n",
      "sigmoid out = tensor([[0.8265, 0.8139],\n",
      "        [0.2111, 0.0738],\n",
      "        [0.2158, 0.7180]], grad_fn=<SigmoidBackward0>)\n",
      "output=0.7995781898498535 \n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, 2, requires_grad=True)\n",
    "print(f\"input = {input}\")\n",
    "target = torch.rand(3, 2, requires_grad=False)\n",
    "print(f\"target = {target}\")\n",
    "print(f\"sigmoid out = {m(input)}\")\n",
    "output = loss(m(input), target)\n",
    "print(f\"output={output} \")\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7a5ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "y dtype =torch.float32\n",
      "torch.float32\n",
      "tensor(0.7851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_605/191361512.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  id_tensor = torch.squeeze(torch.tensor(id_list),dim = 1)\n",
      "/tmp/ipykernel_605/191361512.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tok_type_tensor = torch.squeeze(torch.tensor(tok_type_list),dim = 1)\n",
      "/tmp/ipykernel_605/191361512.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  att_mask_tensor = torch.squeeze(torch.tensor(att_list),dim = 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_dict,_ = train_dataset[85]\n",
    "#print(x)\n",
    "y = torch.tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
    "\n",
    "print(y)\n",
    "print(f\"y dtype ={y.dtype}\")\n",
    "m_gpu = clf_model()\n",
    "m_gpu.to(device)\n",
    "id_list = x_dict['id']\n",
    "id_tensor = torch.squeeze(torch.tensor(id_list),dim = 1)\n",
    "tok_type_list = x_dict['token_type']\n",
    "tok_type_tensor = torch.squeeze(torch.tensor(tok_type_list),dim = 1)\n",
    "att_list = x_dict['attention_mask']\n",
    "att_mask_tensor = torch.squeeze(torch.tensor(att_list),dim = 1)\n",
    "ids_gpu = id_tensor.to(device)\n",
    "token_type_gpu = tok_type_tensor.to(device)\n",
    "att_mask_gpu = att_mask_tensor.to(device)\n",
    "labal_vec_gpu = y.to(device)\n",
    "\n",
    "logits = m_gpu(ids_gpu ,token_type_gpu,att_mask_gpu)\n",
    "print(logits.dtype)\n",
    "loss = nn.BCELoss()\n",
    "output = loss(logits, labal_vec_gpu)\n",
    "output.backward()\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7850b7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 29])\n"
     ]
    }
   ],
   "source": [
    "y_test = torch.tensor([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf4b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
